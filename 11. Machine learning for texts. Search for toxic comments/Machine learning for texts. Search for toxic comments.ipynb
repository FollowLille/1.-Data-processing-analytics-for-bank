{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "### Инструкция по выполнению проекта\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# План работы:\n",
    "\n",
    "1) [Изучение и обработка данных.](#id_1)\n",
    "\n",
    "2) [Обучение моделей, подборка гиперпараметров.](#id_2)\n",
    "\n",
    "3) [Вывод.](#id_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='id_1'></a>\n",
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier \n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "data.info()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас имеется: 159571 комментариев на английском языке, а так же колонка Toxic - которая является целевым признаком и отвечает на вопрос \"Токсичен ли данный комментарий\"\n",
    "Текст на английском языке, он не обработан, его следует лемматизировать. Формат столбца - obj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Далее у меня зависал юпитер и ноутбук при работе с такой большой базой данных, хотя код был написан верно. \n",
    "# В результате чего мне пришлось сократить исходный датафрейм. Ошибка выдавалась при лемматизации.\n",
    "data = data.sample(n=80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишем функции для очищения и лемматизации текста\n",
    "corpus = list(data['text'])\n",
    "\n",
    "def clear_text(text):\n",
    "    text1 = re.sub(r'[^a-zA-Z ]', ' ', str(text))\n",
    "    text1 = \" \".join(text1.split()) \n",
    "    return text1\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ukraine is Poland Ukraine isn t Russia or Poland Dude you are reported for highly offensive citation such a one above'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим, работают ли функции\n",
    "lemmatize_text(clear_text(corpus[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemma_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>If these people are refugees fleeing persecuti...</td>\n",
       "      <td>0</td>\n",
       "      <td>If these people are refugee fleeing persecutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>\"\\n\\n Ukraine is Poland. \\n\\n\"\"Ukraine isn't R...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ukraine is Poland Ukraine isn t Russia or Pola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\"\\nI speak Spanish. Check out this!!. Wow, som...</td>\n",
       "      <td>0</td>\n",
       "      <td>I speak Spanish Check out this Wow someday may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Frustrated Father \\n\\nEight years ago my wife ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Frustrated Father Eight year ago my wife got a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\"\\n\\n Please do not vandalize pages, as you di...</td>\n",
       "      <td>0</td>\n",
       "      <td>Please do not vandalize page a you did with th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  If these people are refugees fleeing persecuti...      0   \n",
       "1  \"\\n\\n Ukraine is Poland. \\n\\n\"\"Ukraine isn't R...      0   \n",
       "2  \"\\nI speak Spanish. Check out this!!. Wow, som...      0   \n",
       "3  Frustrated Father \\n\\nEight years ago my wife ...      0   \n",
       "4  \"\\n\\n Please do not vandalize pages, as you di...      0   \n",
       "\n",
       "                                          lemma_text  \n",
       "0  If these people are refugee fleeing persecutio...  \n",
       "1  Ukraine is Poland Ukraine isn t Russia or Pola...  \n",
       "2  I speak Spanish Check out this Wow someday may...  \n",
       "3  Frustrated Father Eight year ago my wife got a...  \n",
       "4  Please do not vandalize page a you did with th...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Функции работают корректно, можем начинать обрабатывать датафрейм\n",
    "data['lemma_text'] = 1\n",
    "for i in range(len(data)):\n",
    "    data.lemma_text[i] = lemmatize_text(clear_text(corpus[i]))\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['lemma_text']\n",
    "target = data['toxic']\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state = 12345, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf = count_tf_idf.fit_transform(features_train)\n",
    "tf_idf2 = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, данные загружены, обработаны и готовы к использованию. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='id_2'></a>\n",
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7023764617125613"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(tf_idf, target_train)\n",
    "prediction = model.predict(tf_idf2)\n",
    "f1_score(target_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.70']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создадим 2 списка, в которые мы будем добавлять результаты\n",
    "models = []\n",
    "results = []\n",
    "models.append(\"LogisticRegression\")\n",
    "results.append('0.70')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Случайный Лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.0\n",
      "101 0.3509803921568628\n",
      "201 0.551405791019723\n",
      "301 0.6248037676609105\n",
      "401 0.681203007518797\n",
      "501 0.6740988480118916\n",
      "601 0.6885608856088561\n",
      "701 0.6830340784170026\n",
      "801 0.6851032448377581\n",
      "901 0.6616199848599545\n",
      "1001 0.6741488963711185\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1, 1002, 100):   \n",
    "    model = RandomForestClassifier(max_depth=depth, random_state=123)\n",
    "    model.fit(tf_idf, target_train)\n",
    "    prediction = model.predict(tf_idf2)\n",
    "    print(depth, f1_score(target_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5553447185325744\n",
      "101 0.703288490284006\n",
      "201 0.713276310896244\n",
      "301 0.7156644394951743\n",
      "401 0.7157738095238095\n"
     ]
    }
   ],
   "source": [
    "for est in range (1, 402, 100):\n",
    "    model = RandomForestClassifier(max_depth=601, n_estimators=est, random_state=123)\n",
    "    model.fit(tf_idf, target_train)\n",
    "    prediction = model.predict(tf_idf2)\n",
    "    print(est, f1_score(target_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('RandomForest')\n",
    "results.append('0.71')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 0.6535036778939218\n",
      "31 0.6829451540195342\n",
      "41 0.6990791896869245\n",
      "51 0.7147016011644832\n",
      "61 0.7230046948356806\n",
      "71 0.7307829817661781\n"
     ]
    }
   ],
   "source": [
    "# Подбираем параметры\n",
    "for est in range (21, 72, 10):\n",
    "    model=LGBMClassifier(n_estimators=est)\n",
    "    model.fit(tf_idf, target_train)\n",
    "    prediction = model.predict(tf_idf2)\n",
    "    print(est, f1_score(target_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.3799421407907425\n",
      "101 0.7307829817661781\n",
      "201 0.7307829817661781\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-89d5e59f2631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1002\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m71\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_idf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_idf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    803\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    806\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    598\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for depth in range (1, 202, 100):\n",
    "    model=LGBMClassifier(n_estimators=71, max_depth=depth)\n",
    "    model.fit(tf_idf, target_train)\n",
    "    prediction = model.predict(tf_idf2)\n",
    "    print(depth, f1_score(target_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('LightGBM')\n",
    "results.append('0.73')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 DecissionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.278974358974359\n",
      "51 0.7147766323024054\n",
      "101 0.7270349787512259\n",
      "151 0.7307692307692308\n",
      "201 0.7229601518026566\n",
      "251 0.723125\n",
      "301 0.7206427688504327\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1, 302, 50):\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=123)\n",
    "    model.fit(tf_idf, target_train)\n",
    "    prediction = model.predict(tf_idf2)\n",
    "    print(depth, f1_score(target_test, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 0.7212806026365348\n",
      "350 0.7250547388176415\n",
      "400 0.7240839336047604\n",
      "450 0.7240839336047604\n",
      "500 0.7244834063869755\n",
      "550 0.7244834063869755\n",
      "600 0.7244834063869755\n"
     ]
    }
   ],
   "source": [
    "for split in range(300, 601, 50):\n",
    "    model = DecisionTreeClassifier(max_depth=151, random_state=123, min_samples_split=split)\n",
    "    model.fit(tf_idf, target_train)\n",
    "    prediction = model.predict(tf_idf2)\n",
    "    print(split, f1_score(target_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('DecissionTree')\n",
    "results.append('0.73')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.122981\n",
      "0:\tlearn: 0.5767293\ttotal: 3.38s\tremaining: 22m 28s\n",
      "1:\tlearn: 0.4894193\ttotal: 6.17s\tremaining: 20m 27s\n",
      "2:\tlearn: 0.4250355\ttotal: 8.77s\tremaining: 19m 21s\n",
      "3:\tlearn: 0.3762148\ttotal: 11.5s\tremaining: 18m 56s\n",
      "4:\tlearn: 0.3395581\ttotal: 14.3s\tremaining: 18m 46s\n",
      "5:\tlearn: 0.3133912\ttotal: 17s\tremaining: 18m 34s\n",
      "6:\tlearn: 0.2938120\ttotal: 19.7s\tremaining: 18m 23s\n",
      "7:\tlearn: 0.2789433\ttotal: 22.4s\tremaining: 18m 15s\n",
      "8:\tlearn: 0.2671839\ttotal: 25.1s\tremaining: 18m 9s\n",
      "9:\tlearn: 0.2562324\ttotal: 28s\tremaining: 18m 10s\n",
      "10:\tlearn: 0.2486485\ttotal: 30.7s\tremaining: 18m 4s\n",
      "11:\tlearn: 0.2429889\ttotal: 33.4s\tremaining: 17m 58s\n",
      "12:\tlearn: 0.2381412\ttotal: 36.1s\tremaining: 17m 53s\n",
      "13:\tlearn: 0.2340736\ttotal: 38.8s\tremaining: 17m 48s\n",
      "14:\tlearn: 0.2303018\ttotal: 41.5s\tremaining: 17m 44s\n",
      "15:\tlearn: 0.2267575\ttotal: 44.3s\tremaining: 17m 42s\n",
      "16:\tlearn: 0.2238710\ttotal: 47.1s\tremaining: 17m 40s\n",
      "17:\tlearn: 0.2207631\ttotal: 49.9s\tremaining: 17m 38s\n",
      "18:\tlearn: 0.2186865\ttotal: 52.6s\tremaining: 17m 33s\n",
      "19:\tlearn: 0.2166469\ttotal: 55.4s\tremaining: 17m 31s\n",
      "20:\tlearn: 0.2147227\ttotal: 58.1s\tremaining: 17m 27s\n",
      "21:\tlearn: 0.2132535\ttotal: 1m\tremaining: 17m 25s\n",
      "22:\tlearn: 0.2113898\ttotal: 1m 3s\tremaining: 17m 25s\n",
      "23:\tlearn: 0.2097523\ttotal: 1m 6s\tremaining: 17m 22s\n",
      "24:\tlearn: 0.2074386\ttotal: 1m 9s\tremaining: 17m 20s\n",
      "25:\tlearn: 0.2062280\ttotal: 1m 12s\tremaining: 17m 17s\n",
      "26:\tlearn: 0.2045954\ttotal: 1m 14s\tremaining: 17m 15s\n",
      "27:\tlearn: 0.2034029\ttotal: 1m 17s\tremaining: 17m 12s\n",
      "28:\tlearn: 0.2020540\ttotal: 1m 20s\tremaining: 17m 9s\n",
      "29:\tlearn: 0.2009259\ttotal: 1m 23s\tremaining: 17m 6s\n",
      "30:\tlearn: 0.1998534\ttotal: 1m 25s\tremaining: 17m 3s\n",
      "31:\tlearn: 0.1985518\ttotal: 1m 28s\tremaining: 17m\n",
      "32:\tlearn: 0.1975783\ttotal: 1m 31s\tremaining: 16m 57s\n",
      "33:\tlearn: 0.1965943\ttotal: 1m 34s\tremaining: 16m 54s\n",
      "34:\tlearn: 0.1957783\ttotal: 1m 36s\tremaining: 16m 51s\n",
      "35:\tlearn: 0.1949512\ttotal: 1m 39s\tremaining: 16m 48s\n",
      "36:\tlearn: 0.1939103\ttotal: 1m 42s\tremaining: 16m 45s\n",
      "37:\tlearn: 0.1931177\ttotal: 1m 45s\tremaining: 16m 42s\n",
      "38:\tlearn: 0.1919099\ttotal: 1m 47s\tremaining: 16m 39s\n",
      "39:\tlearn: 0.1908613\ttotal: 1m 50s\tremaining: 16m 36s\n",
      "40:\tlearn: 0.1900832\ttotal: 1m 53s\tremaining: 16m 33s\n",
      "41:\tlearn: 0.1893580\ttotal: 1m 56s\tremaining: 16m 30s\n",
      "42:\tlearn: 0.1883770\ttotal: 1m 58s\tremaining: 16m 27s\n",
      "43:\tlearn: 0.1873692\ttotal: 2m 1s\tremaining: 16m 24s\n",
      "44:\tlearn: 0.1867088\ttotal: 2m 4s\tremaining: 16m 22s\n",
      "45:\tlearn: 0.1859722\ttotal: 2m 7s\tremaining: 16m 19s\n",
      "46:\tlearn: 0.1852062\ttotal: 2m 10s\tremaining: 16m 16s\n",
      "47:\tlearn: 0.1844220\ttotal: 2m 12s\tremaining: 16m 14s\n",
      "48:\tlearn: 0.1835545\ttotal: 2m 15s\tremaining: 16m 11s\n",
      "49:\tlearn: 0.1826644\ttotal: 2m 18s\tremaining: 16m 8s\n",
      "50:\tlearn: 0.1820023\ttotal: 2m 21s\tremaining: 16m 5s\n",
      "51:\tlearn: 0.1814021\ttotal: 2m 23s\tremaining: 16m 3s\n",
      "52:\tlearn: 0.1807576\ttotal: 2m 26s\tremaining: 16m\n",
      "53:\tlearn: 0.1800855\ttotal: 2m 29s\tremaining: 15m 57s\n",
      "54:\tlearn: 0.1795449\ttotal: 2m 32s\tremaining: 15m 54s\n",
      "55:\tlearn: 0.1788792\ttotal: 2m 35s\tremaining: 15m 52s\n",
      "56:\tlearn: 0.1781581\ttotal: 2m 37s\tremaining: 15m 49s\n",
      "57:\tlearn: 0.1776392\ttotal: 2m 40s\tremaining: 15m 47s\n",
      "58:\tlearn: 0.1770251\ttotal: 2m 43s\tremaining: 15m 44s\n",
      "59:\tlearn: 0.1765368\ttotal: 2m 46s\tremaining: 15m 41s\n",
      "60:\tlearn: 0.1758412\ttotal: 2m 49s\tremaining: 15m 39s\n",
      "61:\tlearn: 0.1753869\ttotal: 2m 51s\tremaining: 15m 37s\n",
      "62:\tlearn: 0.1749012\ttotal: 2m 54s\tremaining: 15m 33s\n",
      "63:\tlearn: 0.1745061\ttotal: 2m 57s\tremaining: 15m 30s\n",
      "64:\tlearn: 0.1738676\ttotal: 3m\tremaining: 15m 28s\n",
      "65:\tlearn: 0.1733415\ttotal: 3m 3s\tremaining: 15m 26s\n",
      "66:\tlearn: 0.1728262\ttotal: 3m 5s\tremaining: 15m 23s\n",
      "67:\tlearn: 0.1722881\ttotal: 3m 8s\tremaining: 15m 20s\n",
      "68:\tlearn: 0.1718140\ttotal: 3m 11s\tremaining: 15m 17s\n",
      "69:\tlearn: 0.1714219\ttotal: 3m 14s\tremaining: 15m 15s\n",
      "70:\tlearn: 0.1709010\ttotal: 3m 17s\tremaining: 15m 12s\n",
      "71:\tlearn: 0.1704370\ttotal: 3m 19s\tremaining: 15m 10s\n",
      "72:\tlearn: 0.1700471\ttotal: 3m 22s\tremaining: 15m 7s\n",
      "73:\tlearn: 0.1696103\ttotal: 3m 25s\tremaining: 15m 4s\n",
      "74:\tlearn: 0.1691191\ttotal: 3m 28s\tremaining: 15m 2s\n",
      "75:\tlearn: 0.1687264\ttotal: 3m 31s\tremaining: 14m 59s\n",
      "76:\tlearn: 0.1683136\ttotal: 3m 33s\tremaining: 14m 57s\n",
      "77:\tlearn: 0.1679453\ttotal: 3m 36s\tremaining: 14m 54s\n",
      "78:\tlearn: 0.1675462\ttotal: 3m 39s\tremaining: 14m 51s\n",
      "79:\tlearn: 0.1668953\ttotal: 3m 42s\tremaining: 14m 49s\n",
      "80:\tlearn: 0.1665730\ttotal: 3m 45s\tremaining: 14m 46s\n",
      "81:\tlearn: 0.1662424\ttotal: 3m 47s\tremaining: 14m 43s\n",
      "82:\tlearn: 0.1658095\ttotal: 3m 50s\tremaining: 14m 41s\n",
      "83:\tlearn: 0.1654533\ttotal: 3m 53s\tremaining: 14m 38s\n",
      "84:\tlearn: 0.1650337\ttotal: 3m 56s\tremaining: 14m 35s\n",
      "85:\tlearn: 0.1642979\ttotal: 3m 59s\tremaining: 14m 33s\n",
      "86:\tlearn: 0.1639427\ttotal: 4m 2s\tremaining: 14m 30s\n",
      "87:\tlearn: 0.1635159\ttotal: 4m 4s\tremaining: 14m 28s\n",
      "88:\tlearn: 0.1631429\ttotal: 4m 7s\tremaining: 14m 25s\n",
      "89:\tlearn: 0.1628214\ttotal: 4m 10s\tremaining: 14m 22s\n",
      "90:\tlearn: 0.1624074\ttotal: 4m 13s\tremaining: 14m 20s\n",
      "91:\tlearn: 0.1620062\ttotal: 4m 16s\tremaining: 14m 17s\n",
      "92:\tlearn: 0.1617370\ttotal: 4m 18s\tremaining: 14m 14s\n",
      "93:\tlearn: 0.1612442\ttotal: 4m 21s\tremaining: 14m 11s\n",
      "94:\tlearn: 0.1608571\ttotal: 4m 24s\tremaining: 14m 8s\n",
      "95:\tlearn: 0.1604607\ttotal: 4m 27s\tremaining: 14m 6s\n",
      "96:\tlearn: 0.1601770\ttotal: 4m 29s\tremaining: 14m 3s\n",
      "97:\tlearn: 0.1598655\ttotal: 4m 32s\tremaining: 14m\n",
      "98:\tlearn: 0.1594910\ttotal: 4m 35s\tremaining: 13m 57s\n",
      "99:\tlearn: 0.1592079\ttotal: 4m 38s\tremaining: 13m 54s\n",
      "100:\tlearn: 0.1588714\ttotal: 4m 40s\tremaining: 13m 51s\n",
      "101:\tlearn: 0.1585802\ttotal: 4m 43s\tremaining: 13m 49s\n",
      "102:\tlearn: 0.1582327\ttotal: 4m 46s\tremaining: 13m 46s\n",
      "103:\tlearn: 0.1579837\ttotal: 4m 49s\tremaining: 13m 43s\n",
      "104:\tlearn: 0.1574053\ttotal: 4m 52s\tremaining: 13m 41s\n",
      "105:\tlearn: 0.1570929\ttotal: 4m 55s\tremaining: 13m 38s\n",
      "106:\tlearn: 0.1567550\ttotal: 4m 57s\tremaining: 13m 35s\n",
      "107:\tlearn: 0.1563975\ttotal: 5m\tremaining: 13m 33s\n",
      "108:\tlearn: 0.1558324\ttotal: 5m 3s\tremaining: 13m 30s\n",
      "109:\tlearn: 0.1554910\ttotal: 5m 6s\tremaining: 13m 27s\n",
      "110:\tlearn: 0.1551815\ttotal: 5m 9s\tremaining: 13m 24s\n",
      "111:\tlearn: 0.1549362\ttotal: 5m 11s\tremaining: 13m 22s\n",
      "112:\tlearn: 0.1545602\ttotal: 5m 14s\tremaining: 13m 19s\n",
      "113:\tlearn: 0.1542602\ttotal: 5m 17s\tremaining: 13m 16s\n",
      "114:\tlearn: 0.1540634\ttotal: 5m 20s\tremaining: 13m 13s\n",
      "115:\tlearn: 0.1537959\ttotal: 5m 23s\tremaining: 13m 11s\n",
      "116:\tlearn: 0.1535240\ttotal: 5m 25s\tremaining: 13m 8s\n",
      "117:\tlearn: 0.1530910\ttotal: 5m 28s\tremaining: 13m 5s\n",
      "118:\tlearn: 0.1528225\ttotal: 5m 31s\tremaining: 13m 3s\n",
      "119:\tlearn: 0.1525095\ttotal: 5m 34s\tremaining: 13m\n",
      "120:\tlearn: 0.1522504\ttotal: 5m 37s\tremaining: 12m 57s\n",
      "121:\tlearn: 0.1518933\ttotal: 5m 40s\tremaining: 12m 54s\n",
      "122:\tlearn: 0.1516880\ttotal: 5m 42s\tremaining: 12m 52s\n",
      "123:\tlearn: 0.1513966\ttotal: 5m 45s\tremaining: 12m 49s\n",
      "124:\tlearn: 0.1511436\ttotal: 5m 48s\tremaining: 12m 46s\n",
      "125:\tlearn: 0.1508424\ttotal: 5m 51s\tremaining: 12m 44s\n",
      "126:\tlearn: 0.1505249\ttotal: 5m 54s\tremaining: 12m 41s\n",
      "127:\tlearn: 0.1503280\ttotal: 5m 57s\tremaining: 12m 38s\n",
      "128:\tlearn: 0.1500733\ttotal: 5m 59s\tremaining: 12m 36s\n",
      "129:\tlearn: 0.1499065\ttotal: 6m 2s\tremaining: 12m 33s\n",
      "130:\tlearn: 0.1495697\ttotal: 6m 5s\tremaining: 12m 31s\n",
      "131:\tlearn: 0.1493814\ttotal: 6m 8s\tremaining: 12m 28s\n",
      "132:\tlearn: 0.1489642\ttotal: 6m 11s\tremaining: 12m 25s\n",
      "133:\tlearn: 0.1486032\ttotal: 6m 14s\tremaining: 12m 22s\n",
      "134:\tlearn: 0.1483520\ttotal: 6m 17s\tremaining: 12m 20s\n",
      "135:\tlearn: 0.1481236\ttotal: 6m 19s\tremaining: 12m 17s\n",
      "136:\tlearn: 0.1478247\ttotal: 6m 22s\tremaining: 12m 14s\n",
      "137:\tlearn: 0.1475030\ttotal: 6m 25s\tremaining: 12m 11s\n",
      "138:\tlearn: 0.1471391\ttotal: 6m 28s\tremaining: 12m 9s\n",
      "139:\tlearn: 0.1469573\ttotal: 6m 31s\tremaining: 12m 6s\n",
      "140:\tlearn: 0.1467513\ttotal: 6m 33s\tremaining: 12m 3s\n",
      "141:\tlearn: 0.1464855\ttotal: 6m 36s\tremaining: 12m\n",
      "142:\tlearn: 0.1462903\ttotal: 6m 39s\tremaining: 11m 58s\n",
      "143:\tlearn: 0.1461234\ttotal: 6m 42s\tremaining: 11m 55s\n",
      "144:\tlearn: 0.1458545\ttotal: 6m 45s\tremaining: 11m 52s\n",
      "145:\tlearn: 0.1455327\ttotal: 6m 48s\tremaining: 11m 50s\n",
      "146:\tlearn: 0.1452946\ttotal: 6m 50s\tremaining: 11m 47s\n",
      "147:\tlearn: 0.1450685\ttotal: 6m 53s\tremaining: 11m 44s\n",
      "148:\tlearn: 0.1448308\ttotal: 6m 56s\tremaining: 11m 42s\n",
      "149:\tlearn: 0.1446553\ttotal: 6m 59s\tremaining: 11m 39s\n",
      "150:\tlearn: 0.1444646\ttotal: 7m 2s\tremaining: 11m 36s\n",
      "151:\tlearn: 0.1441821\ttotal: 7m 5s\tremaining: 11m 34s\n",
      "152:\tlearn: 0.1440369\ttotal: 7m 8s\tremaining: 11m 31s\n",
      "153:\tlearn: 0.1438076\ttotal: 7m 11s\tremaining: 11m 29s\n",
      "154:\tlearn: 0.1436696\ttotal: 7m 14s\tremaining: 11m 26s\n",
      "155:\tlearn: 0.1435333\ttotal: 7m 17s\tremaining: 11m 23s\n",
      "156:\tlearn: 0.1433956\ttotal: 7m 19s\tremaining: 11m 20s\n",
      "157:\tlearn: 0.1432648\ttotal: 7m 22s\tremaining: 11m 17s\n",
      "158:\tlearn: 0.1431452\ttotal: 7m 25s\tremaining: 11m 14s\n",
      "159:\tlearn: 0.1430264\ttotal: 7m 28s\tremaining: 11m 12s\n",
      "160:\tlearn: 0.1428807\ttotal: 7m 31s\tremaining: 11m 9s\n",
      "161:\tlearn: 0.1427079\ttotal: 7m 33s\tremaining: 11m 6s\n",
      "162:\tlearn: 0.1425891\ttotal: 7m 36s\tremaining: 11m 3s\n",
      "163:\tlearn: 0.1423434\ttotal: 7m 39s\tremaining: 11m\n",
      "164:\tlearn: 0.1421672\ttotal: 7m 42s\tremaining: 10m 58s\n",
      "165:\tlearn: 0.1419438\ttotal: 7m 44s\tremaining: 10m 55s\n",
      "166:\tlearn: 0.1416712\ttotal: 7m 47s\tremaining: 10m 52s\n",
      "167:\tlearn: 0.1415014\ttotal: 7m 50s\tremaining: 10m 49s\n",
      "168:\tlearn: 0.1412657\ttotal: 7m 53s\tremaining: 10m 47s\n",
      "169:\tlearn: 0.1410060\ttotal: 7m 56s\tremaining: 10m 44s\n",
      "170:\tlearn: 0.1407460\ttotal: 7m 59s\tremaining: 10m 41s\n",
      "171:\tlearn: 0.1405147\ttotal: 8m 1s\tremaining: 10m 38s\n",
      "172:\tlearn: 0.1403441\ttotal: 8m 4s\tremaining: 10m 35s\n",
      "173:\tlearn: 0.1401425\ttotal: 8m 7s\tremaining: 10m 33s\n",
      "174:\tlearn: 0.1400250\ttotal: 8m 10s\tremaining: 10m 30s\n",
      "175:\tlearn: 0.1398142\ttotal: 8m 13s\tremaining: 10m 27s\n",
      "176:\tlearn: 0.1395803\ttotal: 8m 15s\tremaining: 10m 24s\n",
      "177:\tlearn: 0.1394701\ttotal: 8m 18s\tremaining: 10m 22s\n",
      "178:\tlearn: 0.1393629\ttotal: 8m 21s\tremaining: 10m 19s\n",
      "179:\tlearn: 0.1392598\ttotal: 8m 24s\tremaining: 10m 16s\n",
      "180:\tlearn: 0.1390541\ttotal: 8m 27s\tremaining: 10m 13s\n",
      "181:\tlearn: 0.1387670\ttotal: 8m 30s\tremaining: 10m 11s\n",
      "182:\tlearn: 0.1386206\ttotal: 8m 32s\tremaining: 10m 8s\n",
      "183:\tlearn: 0.1383042\ttotal: 8m 35s\tremaining: 10m 5s\n",
      "184:\tlearn: 0.1381763\ttotal: 8m 38s\tremaining: 10m 2s\n",
      "185:\tlearn: 0.1379462\ttotal: 8m 41s\tremaining: 9m 59s\n",
      "186:\tlearn: 0.1378314\ttotal: 8m 44s\tremaining: 9m 56s\n",
      "187:\tlearn: 0.1375080\ttotal: 8m 47s\tremaining: 9m 54s\n",
      "188:\tlearn: 0.1374041\ttotal: 8m 49s\tremaining: 9m 51s\n",
      "189:\tlearn: 0.1372410\ttotal: 8m 52s\tremaining: 9m 48s\n",
      "190:\tlearn: 0.1369329\ttotal: 8m 55s\tremaining: 9m 46s\n",
      "191:\tlearn: 0.1368283\ttotal: 8m 58s\tremaining: 9m 43s\n",
      "192:\tlearn: 0.1366827\ttotal: 9m 1s\tremaining: 9m 40s\n",
      "193:\tlearn: 0.1364499\ttotal: 9m 4s\tremaining: 9m 37s\n",
      "194:\tlearn: 0.1362795\ttotal: 9m 6s\tremaining: 9m 34s\n",
      "195:\tlearn: 0.1361259\ttotal: 9m 9s\tremaining: 9m 32s\n",
      "196:\tlearn: 0.1360246\ttotal: 9m 12s\tremaining: 9m 29s\n",
      "197:\tlearn: 0.1359010\ttotal: 9m 15s\tremaining: 9m 26s\n",
      "198:\tlearn: 0.1357128\ttotal: 9m 18s\tremaining: 9m 23s\n",
      "199:\tlearn: 0.1355291\ttotal: 9m 20s\tremaining: 9m 20s\n",
      "200:\tlearn: 0.1353743\ttotal: 9m 23s\tremaining: 9m 18s\n",
      "201:\tlearn: 0.1352050\ttotal: 9m 26s\tremaining: 9m 15s\n",
      "202:\tlearn: 0.1349650\ttotal: 9m 29s\tremaining: 9m 12s\n",
      "203:\tlearn: 0.1348717\ttotal: 9m 32s\tremaining: 9m 9s\n",
      "204:\tlearn: 0.1346712\ttotal: 9m 35s\tremaining: 9m 7s\n",
      "205:\tlearn: 0.1344040\ttotal: 9m 38s\tremaining: 9m 4s\n",
      "206:\tlearn: 0.1341969\ttotal: 9m 40s\tremaining: 9m 1s\n",
      "207:\tlearn: 0.1340969\ttotal: 9m 43s\tremaining: 8m 58s\n",
      "208:\tlearn: 0.1339368\ttotal: 9m 46s\tremaining: 8m 56s\n",
      "209:\tlearn: 0.1337831\ttotal: 9m 49s\tremaining: 8m 53s\n",
      "210:\tlearn: 0.1336762\ttotal: 9m 52s\tremaining: 8m 50s\n",
      "211:\tlearn: 0.1335591\ttotal: 9m 54s\tremaining: 8m 47s\n",
      "212:\tlearn: 0.1333193\ttotal: 9m 57s\tremaining: 8m 44s\n",
      "213:\tlearn: 0.1332272\ttotal: 10m\tremaining: 8m 42s\n",
      "214:\tlearn: 0.1329976\ttotal: 10m 3s\tremaining: 8m 39s\n",
      "215:\tlearn: 0.1329082\ttotal: 10m 6s\tremaining: 8m 36s\n",
      "216:\tlearn: 0.1327202\ttotal: 10m 9s\tremaining: 8m 33s\n",
      "217:\tlearn: 0.1325650\ttotal: 10m 11s\tremaining: 8m 30s\n",
      "218:\tlearn: 0.1324770\ttotal: 10m 14s\tremaining: 8m 28s\n",
      "219:\tlearn: 0.1323971\ttotal: 10m 17s\tremaining: 8m 25s\n",
      "220:\tlearn: 0.1322730\ttotal: 10m 20s\tremaining: 8m 22s\n",
      "221:\tlearn: 0.1321708\ttotal: 10m 23s\tremaining: 8m 19s\n",
      "222:\tlearn: 0.1320365\ttotal: 10m 25s\tremaining: 8m 16s\n",
      "223:\tlearn: 0.1318833\ttotal: 10m 28s\tremaining: 8m 14s\n",
      "224:\tlearn: 0.1317529\ttotal: 10m 31s\tremaining: 8m 11s\n",
      "225:\tlearn: 0.1316655\ttotal: 10m 34s\tremaining: 8m 8s\n",
      "226:\tlearn: 0.1315672\ttotal: 10m 37s\tremaining: 8m 5s\n",
      "227:\tlearn: 0.1313436\ttotal: 10m 40s\tremaining: 8m 2s\n",
      "228:\tlearn: 0.1311530\ttotal: 10m 42s\tremaining: 8m\n",
      "229:\tlearn: 0.1309860\ttotal: 10m 45s\tremaining: 7m 57s\n",
      "230:\tlearn: 0.1307995\ttotal: 10m 48s\tremaining: 7m 54s\n",
      "231:\tlearn: 0.1307211\ttotal: 10m 51s\tremaining: 7m 51s\n",
      "232:\tlearn: 0.1306412\ttotal: 10m 54s\tremaining: 7m 48s\n",
      "233:\tlearn: 0.1305508\ttotal: 10m 57s\tremaining: 7m 46s\n",
      "234:\tlearn: 0.1304234\ttotal: 11m\tremaining: 7m 43s\n",
      "235:\tlearn: 0.1302422\ttotal: 11m 2s\tremaining: 7m 40s\n",
      "236:\tlearn: 0.1300760\ttotal: 11m 5s\tremaining: 7m 37s\n",
      "237:\tlearn: 0.1299956\ttotal: 11m 8s\tremaining: 7m 35s\n",
      "238:\tlearn: 0.1299228\ttotal: 11m 11s\tremaining: 7m 32s\n",
      "239:\tlearn: 0.1298478\ttotal: 11m 14s\tremaining: 7m 29s\n",
      "240:\tlearn: 0.1297672\ttotal: 11m 16s\tremaining: 7m 26s\n",
      "241:\tlearn: 0.1295894\ttotal: 11m 19s\tremaining: 7m 23s\n",
      "242:\tlearn: 0.1294615\ttotal: 11m 22s\tremaining: 7m 21s\n",
      "243:\tlearn: 0.1293832\ttotal: 11m 25s\tremaining: 7m 18s\n",
      "244:\tlearn: 0.1292234\ttotal: 11m 28s\tremaining: 7m 15s\n",
      "245:\tlearn: 0.1291553\ttotal: 11m 31s\tremaining: 7m 12s\n",
      "246:\tlearn: 0.1290671\ttotal: 11m 33s\tremaining: 7m 9s\n",
      "247:\tlearn: 0.1290026\ttotal: 11m 36s\tremaining: 7m 7s\n",
      "248:\tlearn: 0.1289142\ttotal: 11m 39s\tremaining: 7m 4s\n",
      "249:\tlearn: 0.1287161\ttotal: 11m 42s\tremaining: 7m 1s\n",
      "250:\tlearn: 0.1286461\ttotal: 11m 45s\tremaining: 6m 58s\n",
      "251:\tlearn: 0.1284941\ttotal: 11m 47s\tremaining: 6m 55s\n",
      "252:\tlearn: 0.1284193\ttotal: 11m 50s\tremaining: 6m 52s\n",
      "253:\tlearn: 0.1282702\ttotal: 11m 53s\tremaining: 6m 50s\n",
      "254:\tlearn: 0.1281741\ttotal: 11m 56s\tremaining: 6m 47s\n",
      "255:\tlearn: 0.1281042\ttotal: 11m 59s\tremaining: 6m 44s\n",
      "256:\tlearn: 0.1280394\ttotal: 12m 2s\tremaining: 6m 41s\n",
      "257:\tlearn: 0.1279717\ttotal: 12m 4s\tremaining: 6m 38s\n",
      "258:\tlearn: 0.1277960\ttotal: 12m 7s\tremaining: 6m 36s\n",
      "259:\tlearn: 0.1275963\ttotal: 12m 10s\tremaining: 6m 33s\n",
      "260:\tlearn: 0.1275294\ttotal: 12m 13s\tremaining: 6m 30s\n",
      "261:\tlearn: 0.1274651\ttotal: 12m 16s\tremaining: 6m 27s\n",
      "262:\tlearn: 0.1272585\ttotal: 12m 18s\tremaining: 6m 24s\n",
      "263:\tlearn: 0.1271512\ttotal: 12m 21s\tremaining: 6m 22s\n",
      "264:\tlearn: 0.1270126\ttotal: 12m 24s\tremaining: 6m 19s\n",
      "265:\tlearn: 0.1268453\ttotal: 12m 27s\tremaining: 6m 16s\n",
      "266:\tlearn: 0.1266515\ttotal: 12m 30s\tremaining: 6m 13s\n",
      "267:\tlearn: 0.1264890\ttotal: 12m 33s\tremaining: 6m 10s\n",
      "268:\tlearn: 0.1263945\ttotal: 12m 36s\tremaining: 6m 8s\n",
      "269:\tlearn: 0.1263277\ttotal: 12m 38s\tremaining: 6m 5s\n",
      "270:\tlearn: 0.1262578\ttotal: 12m 41s\tremaining: 6m 2s\n",
      "271:\tlearn: 0.1260967\ttotal: 12m 44s\tremaining: 5m 59s\n",
      "272:\tlearn: 0.1259479\ttotal: 12m 47s\tremaining: 5m 57s\n",
      "273:\tlearn: 0.1258856\ttotal: 12m 50s\tremaining: 5m 54s\n",
      "274:\tlearn: 0.1257971\ttotal: 12m 53s\tremaining: 5m 51s\n",
      "275:\tlearn: 0.1255696\ttotal: 12m 55s\tremaining: 5m 48s\n",
      "276:\tlearn: 0.1254702\ttotal: 12m 58s\tremaining: 5m 45s\n",
      "277:\tlearn: 0.1252773\ttotal: 13m 1s\tremaining: 5m 43s\n",
      "278:\tlearn: 0.1252111\ttotal: 13m 4s\tremaining: 5m 40s\n",
      "279:\tlearn: 0.1251431\ttotal: 13m 7s\tremaining: 5m 37s\n",
      "280:\tlearn: 0.1250827\ttotal: 13m 10s\tremaining: 5m 34s\n",
      "281:\tlearn: 0.1249929\ttotal: 13m 12s\tremaining: 5m 31s\n",
      "282:\tlearn: 0.1249011\ttotal: 13m 15s\tremaining: 5m 28s\n",
      "283:\tlearn: 0.1248404\ttotal: 13m 18s\tremaining: 5m 26s\n",
      "284:\tlearn: 0.1247776\ttotal: 13m 21s\tremaining: 5m 23s\n",
      "285:\tlearn: 0.1247168\ttotal: 13m 24s\tremaining: 5m 20s\n",
      "286:\tlearn: 0.1245709\ttotal: 13m 26s\tremaining: 5m 17s\n",
      "287:\tlearn: 0.1245114\ttotal: 13m 29s\tremaining: 5m 14s\n",
      "288:\tlearn: 0.1244508\ttotal: 13m 32s\tremaining: 5m 12s\n",
      "289:\tlearn: 0.1243733\ttotal: 13m 35s\tremaining: 5m 9s\n",
      "290:\tlearn: 0.1242216\ttotal: 13m 38s\tremaining: 5m 6s\n",
      "291:\tlearn: 0.1241624\ttotal: 13m 41s\tremaining: 5m 3s\n",
      "292:\tlearn: 0.1240739\ttotal: 13m 43s\tremaining: 5m\n",
      "293:\tlearn: 0.1240139\ttotal: 13m 46s\tremaining: 4m 58s\n",
      "294:\tlearn: 0.1239374\ttotal: 13m 49s\tremaining: 4m 55s\n",
      "295:\tlearn: 0.1238694\ttotal: 13m 52s\tremaining: 4m 52s\n",
      "296:\tlearn: 0.1237072\ttotal: 13m 55s\tremaining: 4m 49s\n",
      "297:\tlearn: 0.1236512\ttotal: 13m 57s\tremaining: 4m 46s\n",
      "298:\tlearn: 0.1234836\ttotal: 14m\tremaining: 4m 44s\n",
      "299:\tlearn: 0.1234233\ttotal: 14m 3s\tremaining: 4m 41s\n",
      "300:\tlearn: 0.1233562\ttotal: 14m 6s\tremaining: 4m 38s\n",
      "301:\tlearn: 0.1231505\ttotal: 14m 9s\tremaining: 4m 35s\n",
      "302:\tlearn: 0.1230916\ttotal: 14m 12s\tremaining: 4m 32s\n",
      "303:\tlearn: 0.1230361\ttotal: 14m 15s\tremaining: 4m 30s\n",
      "304:\tlearn: 0.1229815\ttotal: 14m 17s\tremaining: 4m 27s\n",
      "305:\tlearn: 0.1228298\ttotal: 14m 20s\tremaining: 4m 24s\n",
      "306:\tlearn: 0.1226479\ttotal: 14m 23s\tremaining: 4m 21s\n",
      "307:\tlearn: 0.1225839\ttotal: 14m 26s\tremaining: 4m 18s\n",
      "308:\tlearn: 0.1224585\ttotal: 14m 29s\tremaining: 4m 16s\n",
      "309:\tlearn: 0.1224037\ttotal: 14m 32s\tremaining: 4m 13s\n",
      "310:\tlearn: 0.1222363\ttotal: 14m 34s\tremaining: 4m 10s\n",
      "311:\tlearn: 0.1221628\ttotal: 14m 37s\tremaining: 4m 7s\n",
      "312:\tlearn: 0.1219519\ttotal: 14m 40s\tremaining: 4m 4s\n",
      "313:\tlearn: 0.1217862\ttotal: 14m 43s\tremaining: 4m 2s\n",
      "314:\tlearn: 0.1217332\ttotal: 14m 46s\tremaining: 3m 59s\n",
      "315:\tlearn: 0.1216796\ttotal: 14m 49s\tremaining: 3m 56s\n",
      "316:\tlearn: 0.1215365\ttotal: 14m 52s\tremaining: 3m 53s\n",
      "317:\tlearn: 0.1214734\ttotal: 14m 55s\tremaining: 3m 50s\n",
      "318:\tlearn: 0.1213072\ttotal: 14m 58s\tremaining: 3m 48s\n",
      "319:\tlearn: 0.1212523\ttotal: 15m 1s\tremaining: 3m 45s\n",
      "320:\tlearn: 0.1211486\ttotal: 15m 3s\tremaining: 3m 42s\n",
      "321:\tlearn: 0.1209559\ttotal: 15m 6s\tremaining: 3m 39s\n",
      "322:\tlearn: 0.1208821\ttotal: 15m 9s\tremaining: 3m 36s\n",
      "323:\tlearn: 0.1207481\ttotal: 15m 12s\tremaining: 3m 34s\n",
      "324:\tlearn: 0.1206153\ttotal: 15m 15s\tremaining: 3m 31s\n",
      "325:\tlearn: 0.1204799\ttotal: 15m 18s\tremaining: 3m 28s\n",
      "326:\tlearn: 0.1204264\ttotal: 15m 21s\tremaining: 3m 25s\n",
      "327:\tlearn: 0.1202864\ttotal: 15m 24s\tremaining: 3m 22s\n",
      "328:\tlearn: 0.1202371\ttotal: 15m 27s\tremaining: 3m 20s\n",
      "329:\tlearn: 0.1201764\ttotal: 15m 29s\tremaining: 3m 17s\n",
      "330:\tlearn: 0.1200315\ttotal: 15m 32s\tremaining: 3m 14s\n",
      "331:\tlearn: 0.1199719\ttotal: 15m 35s\tremaining: 3m 11s\n",
      "332:\tlearn: 0.1199158\ttotal: 15m 38s\tremaining: 3m 8s\n",
      "333:\tlearn: 0.1197670\ttotal: 15m 41s\tremaining: 3m 5s\n",
      "334:\tlearn: 0.1197168\ttotal: 15m 43s\tremaining: 3m 3s\n",
      "335:\tlearn: 0.1196261\ttotal: 15m 46s\tremaining: 3m\n",
      "336:\tlearn: 0.1195000\ttotal: 15m 49s\tremaining: 2m 57s\n",
      "337:\tlearn: 0.1193744\ttotal: 15m 52s\tremaining: 2m 54s\n",
      "338:\tlearn: 0.1193248\ttotal: 15m 55s\tremaining: 2m 51s\n",
      "339:\tlearn: 0.1192709\ttotal: 15m 57s\tremaining: 2m 49s\n",
      "340:\tlearn: 0.1191603\ttotal: 16m\tremaining: 2m 46s\n",
      "341:\tlearn: 0.1189875\ttotal: 16m 3s\tremaining: 2m 43s\n",
      "342:\tlearn: 0.1188635\ttotal: 16m 6s\tremaining: 2m 40s\n",
      "343:\tlearn: 0.1188013\ttotal: 16m 9s\tremaining: 2m 37s\n",
      "344:\tlearn: 0.1187509\ttotal: 16m 12s\tremaining: 2m 34s\n",
      "345:\tlearn: 0.1185616\ttotal: 16m 15s\tremaining: 2m 32s\n",
      "346:\tlearn: 0.1184678\ttotal: 16m 17s\tremaining: 2m 29s\n",
      "347:\tlearn: 0.1182844\ttotal: 16m 20s\tremaining: 2m 26s\n",
      "348:\tlearn: 0.1181351\ttotal: 16m 23s\tremaining: 2m 23s\n",
      "349:\tlearn: 0.1180533\ttotal: 16m 26s\tremaining: 2m 20s\n",
      "350:\tlearn: 0.1178789\ttotal: 16m 29s\tremaining: 2m 18s\n",
      "351:\tlearn: 0.1177480\ttotal: 16m 32s\tremaining: 2m 15s\n",
      "352:\tlearn: 0.1176116\ttotal: 16m 35s\tremaining: 2m 12s\n",
      "353:\tlearn: 0.1174598\ttotal: 16m 38s\tremaining: 2m 9s\n",
      "354:\tlearn: 0.1174024\ttotal: 16m 41s\tremaining: 2m 6s\n",
      "355:\tlearn: 0.1172827\ttotal: 16m 44s\tremaining: 2m 4s\n",
      "356:\tlearn: 0.1172263\ttotal: 16m 46s\tremaining: 2m 1s\n",
      "357:\tlearn: 0.1171805\ttotal: 16m 49s\tremaining: 1m 58s\n",
      "358:\tlearn: 0.1170715\ttotal: 16m 52s\tremaining: 1m 55s\n",
      "359:\tlearn: 0.1170187\ttotal: 16m 55s\tremaining: 1m 52s\n",
      "360:\tlearn: 0.1168726\ttotal: 16m 58s\tremaining: 1m 50s\n",
      "361:\tlearn: 0.1168236\ttotal: 17m 1s\tremaining: 1m 47s\n",
      "362:\tlearn: 0.1167010\ttotal: 17m 4s\tremaining: 1m 44s\n",
      "363:\tlearn: 0.1166317\ttotal: 17m 7s\tremaining: 1m 41s\n",
      "364:\tlearn: 0.1165868\ttotal: 17m 10s\tremaining: 1m 38s\n",
      "365:\tlearn: 0.1165386\ttotal: 17m 12s\tremaining: 1m 35s\n",
      "366:\tlearn: 0.1164109\ttotal: 17m 15s\tremaining: 1m 33s\n",
      "367:\tlearn: 0.1163374\ttotal: 17m 18s\tremaining: 1m 30s\n",
      "368:\tlearn: 0.1161716\ttotal: 17m 21s\tremaining: 1m 27s\n",
      "369:\tlearn: 0.1161228\ttotal: 17m 24s\tremaining: 1m 24s\n",
      "370:\tlearn: 0.1160467\ttotal: 17m 27s\tremaining: 1m 21s\n",
      "371:\tlearn: 0.1160012\ttotal: 17m 30s\tremaining: 1m 19s\n",
      "372:\tlearn: 0.1158788\ttotal: 17m 33s\tremaining: 1m 16s\n",
      "373:\tlearn: 0.1158361\ttotal: 17m 36s\tremaining: 1m 13s\n",
      "374:\tlearn: 0.1157353\ttotal: 17m 38s\tremaining: 1m 10s\n",
      "375:\tlearn: 0.1156882\ttotal: 17m 41s\tremaining: 1m 7s\n",
      "376:\tlearn: 0.1156417\ttotal: 17m 44s\tremaining: 1m 4s\n",
      "377:\tlearn: 0.1155861\ttotal: 17m 47s\tremaining: 1m 2s\n",
      "378:\tlearn: 0.1154720\ttotal: 17m 50s\tremaining: 59.3s\n",
      "379:\tlearn: 0.1154272\ttotal: 17m 53s\tremaining: 56.5s\n",
      "380:\tlearn: 0.1152858\ttotal: 17m 56s\tremaining: 53.7s\n",
      "381:\tlearn: 0.1152396\ttotal: 17m 58s\tremaining: 50.8s\n",
      "382:\tlearn: 0.1151724\ttotal: 18m 1s\tremaining: 48s\n",
      "383:\tlearn: 0.1151281\ttotal: 18m 4s\tremaining: 45.2s\n",
      "384:\tlearn: 0.1150542\ttotal: 18m 7s\tremaining: 42.4s\n",
      "385:\tlearn: 0.1149886\ttotal: 18m 10s\tremaining: 39.5s\n",
      "386:\tlearn: 0.1148785\ttotal: 18m 12s\tremaining: 36.7s\n",
      "387:\tlearn: 0.1148146\ttotal: 18m 15s\tremaining: 33.9s\n",
      "388:\tlearn: 0.1147249\ttotal: 18m 18s\tremaining: 31.1s\n",
      "389:\tlearn: 0.1146815\ttotal: 18m 21s\tremaining: 28.2s\n",
      "390:\tlearn: 0.1146193\ttotal: 18m 24s\tremaining: 25.4s\n",
      "391:\tlearn: 0.1145748\ttotal: 18m 26s\tremaining: 22.6s\n",
      "392:\tlearn: 0.1144443\ttotal: 18m 29s\tremaining: 19.8s\n",
      "393:\tlearn: 0.1143169\ttotal: 18m 32s\tremaining: 16.9s\n",
      "394:\tlearn: 0.1141084\ttotal: 18m 35s\tremaining: 14.1s\n",
      "395:\tlearn: 0.1140392\ttotal: 18m 38s\tremaining: 11.3s\n",
      "396:\tlearn: 0.1139479\ttotal: 18m 41s\tremaining: 8.47s\n",
      "397:\tlearn: 0.1138499\ttotal: 18m 43s\tremaining: 5.65s\n",
      "398:\tlearn: 0.1138075\ttotal: 18m 46s\tremaining: 2.82s\n",
      "399:\tlearn: 0.1136337\ttotal: 18m 49s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7295552367288379"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=CatBoostClassifier(iterations=400)\n",
    "model.fit(tf_idf, target_train)\n",
    "prediction = model.predict(tf_idf2)\n",
    "f1_score(target_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('CatBoost')\n",
    "results.append('0.73')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 PassiveAggressiveClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.761319534282018"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PassiveAggressiveClassifier(random_state=12345, max_iter=5)\n",
    "model.fit(tf_idf, target_train)\n",
    "prediction = model.predict(tf_idf2)\n",
    "f1_score(target_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('PassiveAggressive')\n",
    "results.append('0.76')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['F1']\n",
    "all_results = pd.DataFrame(results, index=models, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='id_3'></a>\n",
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DecissionTree</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PassiveAggressive</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      F1\n",
       "LogisticRegression  0.70\n",
       "RandomForest        0.71\n",
       "LightGBM            0.73\n",
       "DecissionTree       0.73\n",
       "CatBoost            0.73\n",
       "PassiveAggressive   0.76"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод:\n",
    "\n",
    "Условием данного задания было составить модель с метрикой F1 не менее 0.75. Из всех подобранных моделей подходит только PassiveAggressive. Модели CatBoost, DecissionTree и LightGBM идут примерно одинаково с показателем 0.73, но для уровня задачи этого недостаточно. Еще чуть хуже себя показали модели RandomForest и LogisticRegression (0.71 и 0.70). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}